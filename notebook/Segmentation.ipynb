{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train notebook - Airbus kaggle challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ship Detection- Project AIRBUS 2019\n",
    "## Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EDGE_CROP = 16\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (2,2)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 900\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 1000\n",
    "MAX_TRAIN_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from preprocess.pre_process import multi_rle_encode, rle_encode, rle_decode, masks_as_image, masks_as_color, balancing_train\n",
    "from preprocess.pre_process import make_image_gen, create_aug_gen\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 15556806150764048887)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 15299695838826139865)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:1, XLA_GPU, 17179869184, 13515157328291669043)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5078570136355824245)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 7390353818, 17127939859317017519)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:1, GPU, 7390353818, 14994059700585448282)\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "for device in devices:\n",
    "    print(device)\n",
    "    \n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "K.clear_session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_v2.csv  train\t\t\t\t       train_v2.zip\r\n",
      "test\t\t\t  train_ship_segmentations_v2.csv\r\n",
      "test_v2.zip\t\t  train_ship_segmentations_v2.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls ~/data/airbus_ship_detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '../../data/airbus_ship_detection/'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')# Images for training\n",
    "test_image_dir = os.path.join(ship_dir, 'test')# Images for testing\n",
    "label_dir = os.path.join(ship_dir, 'train_ship_segmentations_v2.csv')# Images for testing\n",
    "masks = pd.read_csv(label_dir) # Markers for ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>198320 10 199088 10 199856 10 200624 10 201392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>254389 9 255157 17 255925 17 256693 17 257461 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>108287 1 109054 3 109821 4 110588 5 111356 5 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...\n",
       "5  000194a2d.jpg  198320 10 199088 10 199856 10 200624 10 201392...\n",
       "6  000194a2d.jpg  55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...\n",
       "7  000194a2d.jpg  254389 9 255157 17 255925 17 256693 17 257461 ...\n",
       "8  0001b1832.jpg                                                NaN\n",
       "9  00021ddc3.jpg  108287 1 109054 3 109821 4 110588 5 111356 5 1..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make balanced train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73457\n",
      "3867\n"
     ]
    }
   ],
   "source": [
    "train_df_ids = balancing_train(df=masks, rate_of_has_ship=1, ship_dir_train=train_image_dir)\n",
    "train_df = train_df_ids.merge(masks, on='ImageId')\n",
    "training_set, validation_set = train_test_split(train_df, test_size=0.05)\n",
    "print(len(training_set))\n",
    "print(len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_images_count_boat = np.unique(train_df_ids.has_ship, return_counts=True)\n",
    "plt.bar(hist_images_count_boat[0], hist_images_count_boat[1], width=0.4, tick_label=hist_images_count_boat[0])\n",
    "plt.title('Histogram of the number of boat on images with boats')\n",
    "plt.xlabel('has_ship')\n",
    "plt.ylabel('Counter of images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_images_count_boat = np.unique(train_df_ids.ships, return_counts=True)\n",
    "plt.bar(hist_images_count_boat[0], hist_images_count_boat[1], width=0.4, tick_label=hist_images_count_boat[0])\n",
    "plt.title('Histogram of the number of boat on images with boats')\n",
    "plt.xlabel('Number of ships in image')\n",
    "plt.ylabel('Counter of images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode all the RLEs into Images\n",
    "We make a generator to produce batches of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (64, 384, 384, 3) 0.0 1.0\n",
      "y (64, 384, 384, 1) 0 1\n"
     ]
    }
   ],
   "source": [
    "train_gen = make_image_gen(training_set, train_image_dir, BATCH_SIZE, IMG_SCALING)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (64, 384, 384, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "AUGMENT_BRIGHTNESS = False\n",
    "\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "aug_gen = create_aug_gen(train_gen, image_gen, label_gen)\n",
    "print('x', next(aug_gen)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from models.unet import get_unet\n",
    "from models.unet_resnet50 import get_unet_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over Union for Objects\n",
    "def IoU(y_true, y_pred, tresh=1e-10):\n",
    "    Intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    Union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (Intersection + tresh) / (Union + tresh), axis=0)\n",
    "# Intersection over Union for Background\n",
    "def back_IoU(y_true, y_pred):\n",
    "    return IoU(1-y_true, 1-y_pred)\n",
    "# Loss function\n",
    "def IoU_loss(in_gt, in_pred):\n",
    "    #return 2 - back_IoU(in_gt, in_pred) - IoU(in_gt, in_pred)\n",
    "    return 1 - IoU(in_gt, in_pred) \n",
    "\n",
    "#Dice\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_loss(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_608:0\", shape=(512,), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1092\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder_608:0\", shape=(512,), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4851c108b8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = get_unet(input_shape=train_x.shape[1:], UPSAMPLE_MODE='SIMPLE', NET_SCALING=NET_SCALING)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet_resnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FilRougeAIRBUS/notebook/models/unet_resnet50.py\u001b[0m in \u001b[0;36mget_unet_resnet50\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_unet_resnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mresnet_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresnet_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 md5_hash='a268eb855778b3df3c7506639542a6af')\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mkeras_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1095\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_608:0\", shape=(512,), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "#model = get_unet(input_shape=train_x.shape[1:], UPSAMPLE_MODE='SIMPLE', NET_SCALING=NET_SCALING)\n",
    "model = get_unet_resnet50(input_shape=train_x.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard, Callback\n",
    "weight_path = \"../weights_models/{}_weights.best.hdf5\".format('model_1')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                   patience=2, verbose=1, mode='min',\n",
    "                                   min_delta=0.001, cooldown=1, min_lr=1e-7)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2,\n",
    "                      patience=2) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "tensorboard =  TensorBoard(log_dir=\"../logs/log1\", update_freq='batch')\n",
    "\n",
    "callbacks_list = [checkpoint, reduceLROnPlat, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=dice_loss, \n",
    "              metrics=[IoU, back_IoU, dice_coef, 'binary_accuracy', true_positive_rate])\n",
    "\n",
    "step_count_train = min(MAX_TRAIN_STEPS, training_set.shape[0]//BATCH_SIZE)\n",
    "training_gen = make_image_gen(training_set, train_image_dir, BATCH_SIZE, IMG_SCALING)\n",
    "training_aug_gen =  create_aug_gen(training_gen, image_gen, label_gen)\n",
    "\n",
    "step_count_valid = validation_set.shape[0]//BATCH_SIZE\n",
    "validation_gen = make_image_gen(validation_set, train_image_dir, BATCH_SIZE, IMG_SCALING)\n",
    "\n",
    "print(\"step_count_train =\", step_count_train)\n",
    "print(\"step_count_valid =\", step_count_valid)\n",
    "\n",
    "\n",
    "loss_history = [model.fit_generator(training_aug_gen,\n",
    "                                 steps_per_epoch=step_count_train,\n",
    "                                 epochs=MAX_TRAIN_EPOCHS,\n",
    "                                 callbacks=callbacks_list,\n",
    "                                 validation_data=validation_gen,\n",
    "                                 validation_steps=step_count_valid,\n",
    "                                workers=1 # the generator is not very thread safe\n",
    "                                           )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(loss_history):\n",
    "    epochs = np.concatenate([mh.epoch for mh in loss_history])\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 15))\n",
    "    \n",
    "    _ = ax1.plot(epochs, np.concatenate([mh.history['loss'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "    \n",
    "    _ = ax2.plot(epochs, np.concatenate([mh.history['IoU'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_IoU'] for mh in loss_history]), 'r-')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('IoU accuracy (%)')\n",
    "    \n",
    "    _ = ax3.plot(epochs, np.concatenate([mh.history['back_IoU'] for mh in loss_history]), 'b-',\n",
    "                 epochs, np.concatenate([mh.history['val_back_IoU'] for mh in loss_history]), 'r-')\n",
    "    ax3.legend(['Training', 'Validation'])\n",
    "    ax3.set_title('back_IoU accuracy (%)')\n",
    "\n",
    "show_loss(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(next(validation_gen)[0])\n",
    "print(pred_y.shape, pred_y.min(axis=0).max(), pred_y.max(axis=0).min(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 20))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Full Resolution Model\n",
    "Here we account for the scaling so everything can happen in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(model_1)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = model_1\n",
    "fullres_model.save('fullres_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "def raw_prediction(img, path=test_image_dir):\n",
    "    c_img = imread(os.path.join(path, img))\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = fullres_model.predict(c_img)[0]\n",
    "    return cur_seg, c_img[0]\n",
    "\n",
    "def smooth(cur_seg):\n",
    "    return binary_opening(cur_seg>0.99, np.expand_dims(disk(2), -1))\n",
    "\n",
    "def predict(img, path=test_image_dir):\n",
    "    cur_seg, c_img = raw_prediction(img, path=path)\n",
    "    return smooth(cur_seg), c_img\n",
    "\n",
    "## Get a sample of each group of ship count\n",
    "samples = valid_df.groupby('ships').apply(lambda x: x.sample(1))\n",
    "fig, m_axs = plt.subplots(samples.shape[0], 4, figsize = (15, samples.shape[0]*4))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2, ax3, ax4), c_img_name in zip(m_axs, samples.ImageId.values):\n",
    "    first_seg, first_img = raw_prediction(c_img_name, train_image_dir)\n",
    "    ax1.imshow(first_img)\n",
    "    ax1.set_title('Image: ' + c_img_name)\n",
    "    ax2.imshow(first_seg[:, :, 0], cmap=get_cmap('jet'))\n",
    "    ax2.set_title('Model Prediction')\n",
    "    reencoded = masks_as_color(multi_rle_encode(smooth(first_seg)[:, :, 0]))\n",
    "    ax3.imshow(reencoded)\n",
    "    ax3.set_title('Prediction Masks')\n",
    "    ground_truth = masks_as_color(masks.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels'])\n",
    "    ax4.imshow(ground_truth)\n",
    "    ax4.set_title('Ground Truth')\n",
    "    \n",
    "fig.savefig('validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
