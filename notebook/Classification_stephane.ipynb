{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Airbus Kaggle Challenge**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I : Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from preprocess.pre_process import multi_rle_encode, rle_encode, rle_decode, masks_as_image, masks_as_color, balancing_train\n",
    "from preprocess.pre_process import make_image_gen, create_aug_gen\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import keras \n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from models.resnet50_classif import get_resnet50_classif\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EDGE_CROP = 16\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 900\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 1000000\n",
    "MAX_TRAIN_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 637212447713652715)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 5119052921696102644)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1835051423032854898)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 15560753152, 11783431029140668752)\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Use of tensorflow:\n",
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "for device in devices:\n",
    "    print(device)\n",
    "    \n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths to folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '../../data/airbus_ship_detection/'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')# Images for training\n",
    "test_image_dir = os.path.join(ship_dir, 'test')# Images for testing\n",
    "model_weights_dir = \"weights_models/\"\n",
    "\n",
    "label_dir = os.path.join(ship_dir, 'train_ship_segmentations_v2_clean.csv')# Images for testing\n",
    "dataframe = pd.read_csv(label_dir, engine=\"python\") # Markers for ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_link_balanced rate:0.5, lenght: 80432\n",
      "data_link_unbalanced rate:0.21, lenght: 187098\n"
     ]
    }
   ],
   "source": [
    "data_link_balanced = balancing_train(dataframe, rate_of_has_ship=0.5, ship_dir_train=train_image_dir)\n",
    "data_link_unbalanced = balancing_train(dataframe, rate_of_has_ship=0.0, ship_dir_train=train_image_dir)\n",
    "\n",
    "print(\"data_link_balanced rate:{0}, lenght: {1}\".format(data_link_balanced.has_ship.sum()/len(data_link_balanced)\n",
    "                                                    ,len(data_link_balanced)))\n",
    "print(\"data_link_unbalanced rate:{0}, lenght: {1}\".format(round(data_link_unbalanced.has_ship.sum()/len(data_link_unbalanced),2)\n",
    "                                                    ,len(data_link_unbalanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set 76410\n",
      "length of validation set 4022\n",
      "length of unbalanced training set  177743\n",
      "length of unbalanced validation set 9355\n"
     ]
    }
   ],
   "source": [
    "training_set, validation_set = train_test_split(data_link_balanced, test_size=0.05)\n",
    "training_set_unbalanced, validation_set_unbalanced = train_test_split(data_link_unbalanced, test_size=0.05)\n",
    "\n",
    "print(\"length of training set\", len(training_set))\n",
    "print(\"length of validation set\", len(validation_set))\n",
    "print(\"length of unbalanced training set \", len(training_set_unbalanced))\n",
    "print(\"length of unbalanced validation set\", len(validation_set_unbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (16, 768, 768, 3) 0.0 1.0\n",
      "y (16,) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train_gen = make_image_gen(training_set, train_image_dir, BATCH_SIZE, (1,1))\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_x.min(), train_x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification at low resolution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First pass of the classification with low resolution images dataset and Imagenet weights\n",
    "- For the low resolution we use the parameter scaling = 3.\n",
    "- We don't start from scratch and we use pre-trained weights from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_files(dataframe, ship_dir_train):\n",
    "    training_set, validation_set = train_test_split(dataframe, test_size=0.05)\n",
    "    \n",
    "    training_set_balanced = balancing_train(training_set, rate_of_has_ship=0.5, ship_dir_train=ship_dir_train)\n",
    "    validation_set_balanced = balancing_train(validation_set, rate_of_has_ship=0.5, ship_dir_train=ship_dir_train)\n",
    "    training_set_unbalanced = balancing_train(training_set, rate_of_has_ship=0.0, ship_dir_train=ship_dir_train)\n",
    "    validation_set_unbalanced = balancing_train(validation_set, rate_of_has_ship=0.0, ship_dir_train=ship_dir_train)\n",
    "\n",
    "    dict_dataset = {'training_set_balanced': training_set_balanced,\n",
    "                   'validation_set_balanced': validation_set_balanced,\n",
    "                   'training_set_unbalanced': training_set_unbalanced,\n",
    "                   'validation_set_unbalanced': validation_set_unbalanced\n",
    "                   }\n",
    "    \n",
    "    return dict_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks_list(weight_path, scaling):\n",
    "    checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min', save_weights_only=False)\n",
    "\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                       patience=2, verbose=1, mode='min',\n",
    "                                       min_delta=0.001, cooldown=1, min_lr=1e-7)\n",
    "\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=2)\n",
    "    tensorboard =  TensorBoard(log_dir=\"../logs/log{0}\".format(str(scaling)), update_freq='batch')\n",
    "    return [checkpoint, reduceLROnPlat, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_generator(training_set, validation_set, scaling, train_image_dir, batch_size):\n",
    "    step_count_train = min(MAX_TRAIN_STEPS, training_set.shape[0]//batch_size)\n",
    "    training_gen = make_image_gen(training_set, train_image_dir, batch_size, (scaling, scaling))\n",
    "    \n",
    "    step_count_valid = validation_set.shape[0]//batch_size\n",
    "    validation_gen = make_image_gen(validation_set, train_image_dir, batch_size, (scaling, scaling))\n",
    "    \n",
    "    return step_count_train, training_gen, step_count_valid, validation_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, nbr_gpu=1, scaling=1, print_details=False):\n",
    "    # Sauvegarde des poids\n",
    "    if nbr_gpu > 1:\n",
    "        # save weights multi-gpu\n",
    "        weights_path_clf_scal = model_weights_dir + \"model_clf_scal{0}_{1}_weights.best.h5\".format(str(scaling), \"p_gpu\")\n",
    "        if print_details:\n",
    "            print(\"Save weights to :\", weights_path_clf_scal)\n",
    "        model.save_weights(weights_path_clf_scal)  # save multi-gpu model weights\n",
    "            \n",
    "        # save weights single-gpu\n",
    "        s_gpu_model = model.layers[-2]   #get single GPU model weights\n",
    "        if print_details:\n",
    "            print(\"Save weights to :\", weights_path_clf_scal)\n",
    "        weights_path_clf_scal = model_weights_dir + \"model_clf_scal{0}_{1}_weights.best.h5\".format(str(scaling), \"s_gpu\")\n",
    "        s_gpu_model.save_weights(weights_path_clf_scal)  # save single-gpu model weights\n",
    "    else:\n",
    "        weights_path_clf_scal = model_weights_dir + \"model_clf_scal{0}_{1}_weights.best.h5\".format(str(scaling), \"s_gpu\")\n",
    "        if print_details:\n",
    "            print(\"Save weights to :\", weights_path_clf_scal)\n",
    "        model.save_weights(weights_path_clf_scal)  # save single-gpu model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_training(dict_dataset, train_image_dir, weights=None, scaling=1, batch_size=BATCH_SIZE,\n",
    "                            nbr_gpu=0, print_details=False, epochs=MAX_TRAIN_EPOCHS, nbr_cpu=1):\n",
    "    train_gen = make_image_gen(dict_dataset['training_set_balanced'], train_image_dir, batch_size, (scaling, scaling))\n",
    "    train_x, train_y = next(train_gen)\n",
    "    \n",
    "    if print_details:\n",
    "        print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "        print('y', train_y.shape, train_x.min(), train_x.max())\n",
    "\n",
    "    # Definition of the model with the input shape\n",
    "    clf_model = get_resnet50_classif(input_shape=train_x.shape[1:])\n",
    "    \n",
    "    # Load weights\n",
    "    if weights is not None:\n",
    "        if print_details:\n",
    "            print(\"Load weights...\")\n",
    "        clf_model.load_weights(weights)\n",
    "\n",
    "    weight_path = model_weights_dir + \"model_clf_checkpoint_scal{0}_weights.hdf5\".format(str(scaling))\n",
    "    callbacks = callbacks_list(weight_path, scaling)\n",
    "   \n",
    "    # Model appliqué sur un jeux équilibré\n",
    "    if print_details:\n",
    "        print(\"Get image generator for balance dataset...\")\n",
    "    step_count_train, training_gen, step_count_valid, validation_gen = get_image_generator(dict_dataset['training_set_balanced'],\n",
    "                                                                                           dict_dataset['validation_set_balanced'],\n",
    "                                                                                           scaling, \n",
    "                                                                                           train_image_dir,\n",
    "                                                                                           batch_size)\n",
    "    if print_details:\n",
    "        print(\"step_count_train =\", step_count_train)\n",
    "        print(\"step_count_valid =\", step_count_valid)\n",
    "    \n",
    "    if nbr_gpu > 1:\n",
    "        model = multi_gpu_model(clf_model, gpus=nbr_gpu)\n",
    "    else:\n",
    "        model = clf_model\n",
    "    \n",
    "    if print_details:\n",
    "        clf_model.summary()\n",
    "        \n",
    "    model.compile(optimizer=Adam(), loss=binary_crossentropy, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"Start model...\")\n",
    "    loss_history1 = [model.fit_generator(training_gen,\n",
    "                                     steps_per_epoch=step_count_train,\n",
    "                                     epochs=epochs,\n",
    "                                     callbacks=callbacks,\n",
    "                                     validation_data=validation_gen,\n",
    "                                     validation_steps=step_count_valid,\n",
    "                                     use_multiprocessing=nbr_cpu>1,\n",
    "                                     workers=nbr_cpu)]\n",
    "    \n",
    "    # save weights\n",
    "    save_model(model, nbr_gpu=nbr_gpu, scaling=scaling, print_details=print_details)\n",
    "    \n",
    "    print(\"Model Evaluation Balanced Data: \", model.evaluate_generator(validation_gen,\n",
    "                                              step_count_valid,\n",
    "                                              workers=1,\n",
    "                                              verbose=1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Model appliqué sur un jeux non équilibré\n",
    "    if print_details:\n",
    "        print(\"Get image generator for balance dataset...\")\n",
    "    step_count_train, training_gen, step_count_valid, validation_gen = get_image_generator(dict_dataset['training_set_unbalanced'],\n",
    "                                                                                           dict_dataset['validation_set_unbalanced'],\n",
    "                                                                                           scaling, \n",
    "                                                                                           train_image_dir,\n",
    "                                                                                           batch_size)\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"step_count_train =\", step_count_train)\n",
    "        print(\"step_count_valid =\", step_count_valid)\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"Start model...\")   \n",
    "    loss_history2 = [model.fit_generator(training_gen,\n",
    "                                 steps_per_epoch=step_count_train,\n",
    "                                 epochs=epochs//2,\n",
    "                                 callbacks=callbacks,\n",
    "                                 validation_data=validation_gen,\n",
    "                                 validation_steps=step_count_valid,\n",
    "                                 use_multiprocessing=nbr_cpu!=1,\n",
    "                                 workers=nbr_cpu)]\n",
    "    \n",
    "    # save weights\n",
    "    save_model(model, nbr_gpu=nbr_gpu, scaling=scaling, print_details=print_details)\n",
    "    \n",
    "    print(\"Model Evaluation Unbalanced Data: \", model.evaluate_generator(validation_gen,\n",
    "                                          step_count_valid,\n",
    "                                          workers=1,\n",
    "                                          verbose=1))\n",
    "\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/FilRougeAIRBUS/notebook/preprocess/pre_process.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ships'] = df['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n"
     ]
    }
   ],
   "source": [
    "dict_dataset = get_list_files(dataframe, train_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (256, 256, 256, 3) 0.0 1.0\n",
      "y (256,) 0.0 1.0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get image generator for balance dataset...\n",
      "step_count_train = 304\n",
      "step_count_valid = 28\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Image (InputLayer)        (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 3)  0           Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256, 256, 3)  0           Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 256, 256, 3)  0           Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 256, 256, 3)  0           Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            23589761    lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Concatenate)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Start model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 603s 2s/step - loss: 0.2110 - acc: 0.9380 - val_loss: 2.2513 - val_acc: 0.7349\n",
      "Epoch 2/2\n",
      "304/304 [==============================] - 507s 2s/step - loss: 0.1712 - acc: 0.9468 - val_loss: 0.5753 - val_acc: 0.8694\n",
      "28/28 [==============================] - 202s 7s/step\n",
      "Model Evaluation Balanced Data:  [0.5111086070537567, 0.8715122767857143]\n",
      "Save weights to : weights_models/model_clf_scal3_p_gpu_weights.best.h5\n",
      "Save weights to : weights_models/model_clf_scal3_s_gpu_weights.best.h5\n",
      "Get image generator for balance dataset...\n",
      "step_count_train = 697\n",
      "step_count_valid = 42\n",
      "Start model...\n",
      "Epoch 1/1\n",
      "697/697 [==============================] - 1194s 2s/step - loss: 0.1496 - acc: 0.9576 - val_loss: 0.3548 - val_acc: 0.8573\n",
      "42/42 [==============================] - 291s 7s/step\n",
      "Model Evaluation Unbalanced Data:  [0.3654882641775267, 0.8543526785714286]\n",
      "Save weights to : weights_models/model_clf_scal3_p_gpu_weights.best.h5\n",
      "Save weights to : weights_models/model_clf_scal3_s_gpu_weights.best.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('object') and format specifier ('%.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a float is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-55180146a9cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m classification_training(dict_dataset, train_image_dir, weights=None, \n\u001b[1;32m      2\u001b[0m                         \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                         epochs=2, nbr_cpu=8)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-244225216899>\u001b[0m in \u001b[0;36mclassification_training\u001b[0;34m(dict_dataset, train_image_dir, weights, scaling, batch_size, nbr_gpu, print_details, epochs, nbr_cpu)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Enregistrements des logs de chaque model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mnp_loss_history1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss_history1_clf_scal{0}.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_loss_history1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mnp_loss_history2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[1;32m   1432\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Mismatch between array dtype ('object') and format specifier ('%.18e')"
     ]
    }
   ],
   "source": [
    "classification_training(dict_dataset, train_image_dir, weights=None, \n",
    "                        scaling=3, batch_size=256, nbr_gpu=4, print_details=True, \n",
    "                        epochs=2, nbr_cpu=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (64, 384, 384, 3) 0.0 1.0\n",
      "y (64,) 0.0 1.0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get image generator for balance dataset...\n",
      "step_count_train = 1216\n",
      "step_count_valid = 111\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Image (InputLayer)        (None, 384, 384, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 384, 384, 3)  0           Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 384, 384, 3)  0           Input_Image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            23589761    lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Concatenate)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Start model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216/1216 [==============================] - 1197s 985ms/step - loss: 0.2562 - acc: 0.9246 - val_loss: 1.0455 - val_acc: 0.7927\n",
      "Epoch 2/5\n",
      "1216/1216 [==============================] - 1150s 945ms/step - loss: 0.2527 - acc: 0.9167 - val_loss: 0.6935 - val_acc: 0.8207\n",
      "Epoch 3/5\n",
      "1216/1216 [==============================] - 1147s 943ms/step - loss: 0.2518 - acc: 0.9170 - val_loss: 0.5878 - val_acc: 0.7565\n",
      "Epoch 4/5\n",
      "1216/1216 [==============================] - 1168s 961ms/step - loss: 0.2281 - acc: 0.9189 - val_loss: 0.3242 - val_acc: 0.8674\n",
      "Epoch 5/5\n",
      "1216/1216 [==============================] - 1158s 952ms/step - loss: 0.2348 - acc: 0.9151 - val_loss: 0.3461 - val_acc: 0.8681\n",
      "111/111 [==============================] - 209s 2s/step\n",
      "Model Evaluation Balanced Data:  [0.3701113920893755, 0.8735923423423423]\n",
      "Save weights to : weights_models/model_clf_scal2_p_gpu_weights.best.h5\n",
      "Save weights to : weights_models/model_clf_scal2_s_gpu_weights.best.h5\n",
      "Get image generator for balance dataset...\n",
      "step_count_train = 2787\n",
      "step_count_valid = 171\n",
      "Start model...\n",
      "Epoch 1/2\n",
      "2787/2787 [==============================] - 2618s 939ms/step - loss: 0.1619 - acc: 0.9491 - val_loss: 0.5410 - val_acc: 0.8448\n",
      "Epoch 2/2\n",
      "2787/2787 [==============================] - 2582s 926ms/step - loss: 0.1748 - acc: 0.9447 - val_loss: 0.5971 - val_acc: 0.8274\n",
      "171/171 [==============================] - 317s 2s/step\n",
      "Model Evaluation Unbalanced Data:  [0.5749671318900516, 0.8343384502923976]\n",
      "Save weights to : weights_models/model_clf_scal2_p_gpu_weights.best.h5\n",
      "Save weights to : weights_models/model_clf_scal2_s_gpu_weights.best.h5\n"
     ]
    }
   ],
   "source": [
    "weights_path3 = model_weights_dir + \"model_clf_scal{0}_{1}_weights.best.h5\".format(str(3), \"s_gpu\")\n",
    "classification_training(dict_dataset, train_image_dir, weights=weights_path3, \n",
    "                        scaling=2, batch_size=64, nbr_gpu=2, print_details=True, \n",
    "                        epochs=MAX_TRAIN_EPOCHS, nbr_cpu=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (8, 768, 768, 3) 0.0 1.0\n",
      "y (8,) 0.0 1.0\n",
      "Load weights...\n",
      "Get image generator for balance dataset...\n",
      "step_count_train = 9730\n",
      "step_count_valid = 909\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Image (InputLayer)     (None, 768, 768, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             multiple                  23587712  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Start model...\n",
      "Epoch 1/2\n",
      "9730/9730 [==============================] - 4784s 492ms/step - loss: 0.3175 - acc: 0.8746 - val_loss: 0.2759 - val_acc: 0.8944\n",
      "Epoch 2/2\n",
      "9730/9730 [==============================] - 4730s 486ms/step - loss: 0.2357 - acc: 0.9105 - val_loss: 0.2874 - val_acc: 0.9163\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2f43b15f0a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m classification_training(dict_dataset, train_image_dir, weights=weights_path2, \n\u001b[1;32m      3\u001b[0m                         \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                         epochs=2, nbr_cpu=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-1ccb30d1ef68>\u001b[0m in \u001b[0;36mclassification_training\u001b[0;34m(dict_dataset, train_image_dir, weights, scaling, batch_size, nbr_gpu, print_details, epochs, nbr_cpu)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# save weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbr_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     print(\"Model Evaluation Balanced Data: \", model.evaluate_generator(validation_gen,\n",
      "\u001b[0;32m<ipython-input-16-52bd94efca06>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, nbr_gpu, scalling, print_details)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ms_gpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path_clf_scal\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save single-gpu model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mweights_path_clf_scal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_weights_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"model_clf_scal{0}_{1}_weights.best.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint_details\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Save weights to :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path_clf_scal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaling' is not defined"
     ]
    }
   ],
   "source": [
    "weights_path2 = model_weights_dir + \"model_clf_scal{0}_{1}_weights.best.h5\".format(str(2), \"s_gpu\")\n",
    "classification_training(dict_dataset, train_image_dir, weights=weights_path2, \n",
    "                        scaling=1, batch_size=8, nbr_gpu=1, print_details=True, \n",
    "                        epochs=2, nbr_cpu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_classification_training(dict_dataset, train_image_dir, weights=None, scaling=1, batch_size=BATCH_SIZE,\n",
    "                            nbr_gpu=0, print_details=False, epochs=MAX_TRAIN_EPOCHS, nbr_cpu=1):\n",
    "    train_gen = make_image_gen(dict_dataset['training_set_balanced'], train_image_dir, batch_size, (scaling, scaling))\n",
    "    train_x, train_y = next(train_gen)\n",
    "    \n",
    "    if print_details:\n",
    "        print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "        print('y', train_y.shape, train_x.min(), train_x.max())\n",
    "\n",
    "    # Definition of the model with the input shape\n",
    "    clf_model = get_resnet50_classif(input_shape=train_x.shape[1:])\n",
    "    \n",
    "    # Load weights\n",
    "    if weights is not None:\n",
    "        if print_details:\n",
    "            print(\"Load weights...\")\n",
    "        clf_model.load_weights(weights)\n",
    "\n",
    "    weight_path = model_weights_dir + \"model_clf_checkpoint_scal{0}_weights.hdf5\".format(str(scaling))\n",
    "    callbacks = callbacks_list(weight_path, scaling)\n",
    "   \n",
    "    # Model appliqué sur un jeux équilibré\n",
    "    if print_details:\n",
    "        print(\"Get image generator for balance dataset...\")\n",
    "    step_count_train, training_gen, step_count_valid, validation_gen = get_image_generator(dict_dataset['training_set_balanced'],\n",
    "                                                                                           dict_dataset['validation_set_balanced'],\n",
    "                                                                                           scaling, \n",
    "                                                                                           train_image_dir,\n",
    "                                                                                           batch_size)\n",
    "    if print_details:\n",
    "        print(\"step_count_train =\", step_count_train)\n",
    "        print(\"step_count_valid =\", step_count_valid)\n",
    "    \n",
    "    if nbr_gpu > 1:\n",
    "        model = multi_gpu_model(clf_model, gpus=nbr_gpu)\n",
    "    else:\n",
    "        model = clf_model\n",
    "    \n",
    "    if print_details:\n",
    "        clf_model.summary()\n",
    "        \n",
    "    model.compile(optimizer=Adam(), loss=binary_crossentropy, \n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"Start model...\")\n",
    "#     loss_history1 = [model.fit_generator(training_gen,\n",
    "#                                      steps_per_epoch=step_count_train,\n",
    "#                                      epochs=epochs,\n",
    "#                                      callbacks=callbacks,\n",
    "#                                      validation_data=validation_gen,\n",
    "#                                      validation_steps=step_count_valid,\n",
    "#                                      use_multiprocessing=nbr_cpu>1,\n",
    "#                                      workers=nbr_cpu)]\n",
    "    \n",
    "    \n",
    "    # save weights\n",
    "    save_model(model, nbr_gpu=nbr_gpu, scaling=scaling, print_details=print_details)\n",
    "    \n",
    "    print(\"Model Evaluation Balanced Data: \", model.evaluate_generator(validation_gen,\n",
    "                                              step_count_valid,\n",
    "                                              workers=1,\n",
    "                                              verbose=1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Model appliqué sur un jeux non équilibré\n",
    "    if print_details:\n",
    "        print(\"Get image generator for balance dataset...\")\n",
    "    step_count_train, training_gen, step_count_valid, validation_gen = get_image_generator(dict_dataset['training_set_unbalanced'],\n",
    "                                                                                           dict_dataset['validation_set_unbalanced'],\n",
    "                                                                                           scaling, \n",
    "                                                                                           train_image_dir,\n",
    "                                                                                           batch_size)\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"step_count_train =\", step_count_train)\n",
    "        print(\"step_count_valid =\", step_count_valid)\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"Start model...\")   \n",
    "    loss_history2 = [model.fit_generator(training_gen,\n",
    "                                 steps_per_epoch=step_count_train,\n",
    "                                 epochs=epochs//2,\n",
    "                                 callbacks=callbacks,\n",
    "                                 validation_data=validation_gen,\n",
    "                                 validation_steps=step_count_valid,\n",
    "                                 use_multiprocessing=nbr_cpu!=1,\n",
    "                                 workers=nbr_cpu)]\n",
    "    \n",
    "    # save weights\n",
    "    save_model(model, nbr_gpu=nbr_gpu, scaling=scaling, print_details=print_details)\n",
    "    \n",
    "    print(\"Model Evaluation Unbalanced Data: \", model.evaluate_generator(validation_gen,\n",
    "                                          step_count_valid,\n",
    "                                          workers=1,\n",
    "                                          verbose=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (8, 768, 768, 3) 0.0 1.0\n",
      "y (8,) 0.0 1.0\n",
      "Load weights...\n",
      "Get image generator for balance dataset...\n",
      "step_count_train = 9730\n",
      "step_count_valid = 909\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Image (InputLayer)     (None, 768, 768, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             multiple                  23587712  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Start model...\n",
      "Save weights to : weights_models/model_clf_scal1_s_gpu_weights.best.h5\n",
      "782/909 [========================>.....] - ETA: 42s"
     ]
    }
   ],
   "source": [
    "weights_path2 = model_weights_dir + \"model_clf_checkpoint_scal{0}_weights.hdf5\".format(str(1))\n",
    "temp_classification_training(dict_dataset, train_image_dir, weights=weights_path2, \n",
    "                        scaling=1, batch_size=8, nbr_gpu=1, print_details=True, \n",
    "                        epochs=2, nbr_cpu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
