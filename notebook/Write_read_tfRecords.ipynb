{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf records for speeding up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webographie:  \n",
    "https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36  \n",
    "https://medium.com/ymedialabs-innovation/how-to-use-tfrecord-with-datasets-and-iterators-in-tensorflow-with-code-samples-ffee57d298af  \n",
    "https://www.tensorflow.org/tutorials/load_data/tf_records#read_the_tfrecord_file  \n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "from preprocess.pre_process import multi_rle_encode, rle_encode, rle_decode, masks_as_image, masks_as_color, balancing_train\n",
    "from preprocess.pre_process import make_image_gen, create_aug_gen\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0024585723876953"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "time.sleep(2)\n",
    "timing = time.time() - start\n",
    "timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "      return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '../../data/airbus_ship_detection/'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')# Images for training\n",
    "test_image_dir = os.path.join(ship_dir, 'test')# Images for testing\n",
    "label_dir = os.path.join(ship_dir, 'train_ship_segmentations_v2.csv')# Images for testing\n",
    "masks = pd.read_csv(label_dir, engine=\"python\") # Markers for ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link_balanced = balancing_train(masks, rate_of_has_ship=0.5, ship_dir_train=train_image_dir)\n",
    "data_link_unbalanced = balancing_train(masks, rate_of_has_ship=0.0, ship_dir_train=train_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_link_balanced rate:0.5, lenght: 80432\n",
      "data_link_unbalanced rate:0.21, lenght: 187099\n"
     ]
    }
   ],
   "source": [
    "print(\"data_link_balanced rate:{0}, lenght: {1}\".format(data_link_balanced.has_ship.sum()/len(data_link_balanced)\n",
    "                                                    ,len(data_link_balanced)))\n",
    "print(\"data_link_unbalanced rate:{0}, lenght: {1}\".format(round(data_link_unbalanced.has_ship.sum()/len(data_link_unbalanced),2)\n",
    "                                                    ,len(data_link_unbalanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>file_size_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>147.625977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>242.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002756f7.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>287.620117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00031f145.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>232.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>166.852539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  ships  has_ship  file_size_kb\n",
       "0  000155de5.jpg      1         1    147.625977\n",
       "1  00021ddc3.jpg      9         1    242.910156\n",
       "2  0002756f7.jpg      2         1    287.620117\n",
       "3  00031f145.jpg      1         1    232.898438\n",
       "4  000532683.jpg      2         1    166.852539"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_link_balanced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80432"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 768, 768, 3)\n",
      "CPU times: user 332 ms, sys: 0 ns, total: 332 ms\n",
      "Wall time: 330 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images_list = []\n",
    "for filename in data_link_unbalanced.ImageId[:10]:\n",
    "        img = imread(os.path.join(train_image_dir,filename))\n",
    "        if img is not None:\n",
    "            images_list.append(img)\n",
    "        else:\n",
    "            print(\"Error image missing\")\n",
    "print(np.array(images_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of images : (187099,)\n",
      "shape of labels : (187099,)\n"
     ]
    }
   ],
   "source": [
    "images_link = np.array(data_link_unbalanced.ImageId)\n",
    "labels = np.array(data_link_unbalanced.has_ship)\n",
    "print(\"shape of images :\", images_link.shape)\n",
    "print(\"shape of labels :\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to(images_link, labels, name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    num_examples = labels.shape[0]\n",
    "    \n",
    "\n",
    "    if images_link.shape[0] != num_examples:\n",
    "        raise ValueError('Images size %d does not match label size %d.' %\n",
    "                         (images_link.shape[0], num_examples))\n",
    "        \n",
    "    img_shape = imread(os.path.join(train_image_dir, images_link[0])).shape    \n",
    "    \n",
    "    rows = img_shape[0]\n",
    "    cols = img_shape[1]\n",
    "    depth = img_shape[2]\n",
    "\n",
    "    filename = os.path.join(ship_dir, name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    start = time.time()\n",
    "    t_per_file = []\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for index in range(num_examples):\n",
    "            if index%100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                t_per_file.append((time.time() - start) / 100)\n",
    "                eta = np.mean(t_per_file) * (num_examples - index)\n",
    "                print(\"ETA:\", round(eta,2), end=\" seconds ==>  \")\n",
    "                print(index, \"/\", num_examples)\n",
    "                start = time.time()\n",
    "            with tf.gfile.FastGFile(os.path.join(train_image_dir, images_link[index]) , 'rb') as fid:\n",
    "                image_data = fid.read()\n",
    "            example = tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                      'label': _int64_feature(int(labels[index])),\n",
    "                      'image_raw': _bytes_feature(image_data)\n",
    "                      }))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_val, labels_train, labels_val = train_test_split(images_link, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA: 236.16 seconds ==>  69700 / 168389\n"
     ]
    }
   ],
   "source": [
    "convert_to(images_train, labels_train, \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to(images_val, labels_val, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filepath):\n",
    "    \n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    \n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=8)\n",
    "    \n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Set the number of datapoints you want to load and shuffle \n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "    \n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create your tf representation of the iterator\n",
    "    image, label = iterator.get_next()\n",
    "\n",
    "    # Bring your picture back in shape\n",
    "    image = tf.reshape(image, [-1, 256, 256, 1])\n",
    "    \n",
    "    # Create a one hot array for your labels\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
